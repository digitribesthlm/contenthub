import { GoogleGenAI, Modality, Part } from "@google/genai";

const imageModel = 'gemini-2.5-flash-image';

// Lazy initialization of Gemini client
let aiClient: GoogleGenAI | null = null;

const getGeminiClient = (): GoogleGenAI => {
    if (!aiClient) {
        const apiKey = import.meta.env.GEMINI_API_KEY;
        if (!apiKey) {
            throw new Error("GEMINI_API_KEY environment variable is not set. Please add it to your .env.local file.");
        }
        aiClient = new GoogleGenAI({ apiKey });
    }
    return aiClient;
};

const getBase64Data = (dataUrl: string): { mimeType: string, data: string } => {
    const [header, base64Data] = dataUrl.split(',');
    if (!base64Data) {
        throw new Error("Invalid base64 image data.");
    }
    const mimeType = header.match(/:(.*?);/)?.[1] || 'image/jpeg';
    return { mimeType, data: base64Data };
};

const processApiResponse = (response: any): string => {
    for (const part of response.candidates[0].content.parts) {
        if (part.inlineData) {
            const base64ImageBytes: string = part.inlineData.data;
            return `data:${part.inlineData.mimeType};base64,${base64ImageBytes}`;
        }
    }
    throw new Error("No image was generated by the API.");
};


export const generateHeroImage = async (contentPrompt: string, stylePrompt: string, styleImageUrl?: string): Promise<string> => {
  try {
    const ai = getGeminiClient();
    const parts: Part[] = [];

    if (styleImageUrl) {
        console.log("‚ú® Using multimodal generation with style image.");
        const { mimeType, data } = getBase64Data(styleImageUrl);
        parts.push({ inlineData: { data, mimeType } });
        parts.push({ text: `Analyze the style, composition, and mood of the provided image. Then, create a new hero image based on the following content brief, ensuring the new image matches the style of the reference image. Content: "${contentPrompt}". Style notes: "${stylePrompt}"` });
    } else {
        console.log("‚ú® Using text-to-image generation.");
        parts.push({ text: `Create a hero image based on the following content brief. Content: "${contentPrompt}". Apply this style: "${stylePrompt}"` });
    }

    console.log("üé® Calling Gemini API...");
    const response = await ai.models.generateContent({
        model: imageModel,
        contents: { parts },
        config: {
            responseModalities: [Modality.IMAGE],
        },
    });
    
    console.log("‚úÖ Image generated successfully");
    return processApiResponse(response);

  } catch (error) {
    console.error("‚ùå Error generating image with Gemini:", error);
    throw new Error(`Failed to generate hero image: ${error instanceof Error ? error.message : String(error)}`);
  }
};


export const editHeroImage = async (baseImage: string, editPrompt: string, stylePrompt: string): Promise<string> => {
    console.log("‚úèÔ∏è Editing image with prompt:", editPrompt);
    try {
        const ai = getGeminiClient();
        const { mimeType, data } = getBase64Data(baseImage);
        
        const imagePart: Part = {
            inlineData: { data, mimeType },
        };

        const textPart: Part = {
            text: `Edit the provided image based on the following instruction: "${editPrompt}". Maintain the overall style. Additional style guidance: "${stylePrompt}"`
        };

        console.log("üé® Calling Gemini API to edit image...");
        const response = await ai.models.generateContent({
            model: imageModel,
            contents: {
              parts: [imagePart, textPart],
            },
            config: {
                responseModalities: [Modality.IMAGE],
            },
        });
        
        console.log("‚úÖ Image edited successfully");
        return processApiResponse(response);

    } catch (error) {
        console.error("‚ùå Error editing image with Gemini:", error);
        throw new Error(`Failed to edit hero image: ${error instanceof Error ? error.message : String(error)}`);
    }
};
